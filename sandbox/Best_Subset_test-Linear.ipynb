{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81575740-c4a9-488d-bac8-c4c8463dd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b527cc7-84da-4287-9f34-fcefdc3524a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "import pytest\n",
    "import sys\n",
    " \n",
    " \n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7d2c35-485f-4b80-8761-2308e75b961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import best_subset as bs_pkgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2b7f862-9e01-4069-8398-a72cefeea660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['const', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
      "       'x11', 'x12', 'x13', 'x14', 'x15', 'weight'],\n",
      "      dtype='object')\n",
      "df shape: (50000, 17)\n",
      "y shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_exaustive_and_return_top(df, features, return_top=100):\n",
    "    mask = df['Models'].notna()  # Ensure we exclude NaN values    \n",
    "    for feature in features:\n",
    "        mask &= df['Models'].str.contains(rf'\\b{feature}\\b', regex=True, na=False)\n",
    "    top =  df[mask] \n",
    "\n",
    "    top['rank'] = top.groupby(\"Var Number\")['Scores'].rank(ascending=False)\n",
    "    top = top[top['rank']<=100]\n",
    "    top.drop('rank', axis=1, inplace=True)\n",
    "    top = top.reset_index(drop=True)\n",
    "    return top\n",
    "\n",
    "\n",
    "def check_if_features_in(df, features):\n",
    "    mask = df['Models'].notna()  # Ensure we exclude NaN values    \n",
    "    for feature in features:\n",
    "        mask &= df['Models'].str.contains(rf'\\b{feature}\\b', regex=True, na=False)\n",
    "    return df[mask]\n",
    "\n",
    "def compare_dataframes(df1: pd.DataFrame, df2: pd.DataFrame):\n",
    "    \"\"\"Compares two pandas DataFrames, rounding floating-point columns to 2 decimal places.\"\"\"\n",
    "    float_cols = df1.select_dtypes(include=['float']).columns\n",
    "    df1_rounded = df1.copy()\n",
    "    df2_rounded = df2.copy()\n",
    "    df1_rounded[float_cols] = df1_rounded[float_cols].round(2)\n",
    "    df2_rounded[float_cols] = df2_rounded[float_cols].round(2)\n",
    "    pd.testing.assert_frame_equal(df1_rounded, df2_rounded, check_dtype=False)\n",
    "    print(\"Dataset Match\")\n",
    "\n",
    "def order_models_field(df):\n",
    "    df['Models'] = df['Models'].apply(\n",
    "        lambda model: \" \".join(\n",
    "            sorted(model.split(\" \"), key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "        )\n",
    "    )\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df \n",
    "\n",
    "def create_synthetic_data_logistic(seed=42, n=50000, p=15):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame X of shape (n, p+1) with columns:\n",
    "      - 'const': all ones (intercept)\n",
    "      - 'x1', 'x2', ... 'x15'\n",
    "    And a Series y with binary (0/1) outcomes drawn from a logistic model.\n",
    "    \n",
    "    Some of the 15 features have nonzero coefficients, others are zero,\n",
    "    so there's meaningful signal to detect in a logistic regression.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 1) Generate random features ~ N(0,1)\n",
    "    X_base = np.random.randn(n, p)\n",
    "    \n",
    "    # 2) Define \"true\" coefficients\n",
    "    #    For instance, let's say 5 features matter:\n",
    "    #    x1, x2, x3, x4, x5 have some nonzero betas.\n",
    "    #    The remaining x6..x15 have 0 effect.\n",
    "    betas_true = np.array([1.5, -2.0, 0.75, 1.25, -0.5] + [0]*(p-5))\n",
    "    #     -> length = 15\n",
    "    \n",
    "    # 3) Linear predictor: X_base dot betas_true\n",
    "    #    shape -> (n, )\n",
    "    lin_pred = X_base.dot(betas_true)\n",
    "    \n",
    "    # 4) Convert linear predictor to probability via logistic function\n",
    "    #    p_i = 1 / (1 + exp(-lin_pred))\n",
    "    prob = 1.0 / (1.0 + np.exp(-lin_pred))\n",
    "    \n",
    "    # 5) Draw binary outcomes y from Bernoulli(prob)\n",
    "    y_vals = np.random.binomial(1, prob)\n",
    "    \n",
    "    # 6) Create a DataFrame for features, plus an intercept column\n",
    "    df = pd.DataFrame(X_base, columns=[f\"x{i+1}\" for i in range(p)])\n",
    "    df.insert(0, \"const\", 1.0)  # intercept\n",
    "    \n",
    "    # 7) Create a Series for y\n",
    "    y = pd.Series(y_vals, name=\"y\")\n",
    "    \n",
    "    return df, y\n",
    "def create_synthetic_data_linear_regression(seed=42, n=50000, p=15, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Creates synthetic data for linear regression.\n",
    "\n",
    "    Args:\n",
    "        seed: Random seed for reproducibility.\n",
    "        n: Number of samples.\n",
    "        p: Number of features (excluding the intercept).\n",
    "        sigma: Standard deviation of the error term.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: A DataFrame `df` containing the features (including 'const' and 'weight') \n",
    "               and a Series `y` representing the target variable.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 1) Generate random features ~ N(0,1)\n",
    "    X_base = np.random.randn(n, p)\n",
    "\n",
    "    # 2) Define \"true\" coefficients (including the intercept)\n",
    "    #    Let's say 5 features have a non-zero effect.\n",
    "    betas_true = np.array([2.0, 1.5, -2.0, 0.75, 1.25, -0.5] + [0] * (p - 5))\n",
    "    # betas_true now includes the intercept (e.g., 2.0) in the first position.\n",
    "\n",
    "    # 3) Generate weights between 0 and 100\n",
    "    weights = np.random.uniform(0, 100, size=n)\n",
    "\n",
    "    # 4) Create a DataFrame for features, plus an intercept column\n",
    "    df = pd.DataFrame(X_base, columns=[f\"x{i + 1}\" for i in range(p)])\n",
    "    df.insert(0, \"const\", 1.0)  # intercept\n",
    "\n",
    "    # 5) Linear predictor: X dot betas_true (including intercept)\n",
    "    #    shape -> (n, )\n",
    "    lin_pred = df.drop(columns=['const']).dot(betas_true[1:]) + betas_true[0] # Account for intercept in betas_true\n",
    "\n",
    "    # 6) Generate the target variable y with added noise:\n",
    "    #    y = linear predictor + error\n",
    "    #    where error ~ N(0, sigma^2)\n",
    "    y_vals = lin_pred + np.random.normal(0, sigma, size=n)\n",
    "\n",
    "    # 7) Add 'weight' column to DataFrame\n",
    "    df['weight'] = weights\n",
    "\n",
    "    # 8) Create a Series for y\n",
    "    y = pd.Series(y_vals, name=\"y\")\n",
    "\n",
    "    return df, y\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def create_synthetic_data_ordinal_logit(seed=42, n_samples=50000, n_features=15, n_classes=3, \n",
    "                                      beta_scale=1.0, class_separation=1.0):\n",
    "    \"\"\"\n",
    "    Creates synthetic data for ordinal logistic regression.\n",
    "\n",
    "    Args:\n",
    "        seed: Random seed for reproducibility\n",
    "        n_samples: Number of observations\n",
    "        n_features: Number of features (excluding intercept)\n",
    "        n_classes: Number of ordinal classes (3-5 recommended)\n",
    "        beta_scale: Scale factor for coefficient magnitudes\n",
    "        class_separation: Controls spread between cutpoints\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (df, y) where df contains features + weights, y contains ordinal labels\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 1. Generate features matrix with intercept\n",
    "    X_base = np.random.randn(n_samples, n_features)\n",
    "    df = pd.DataFrame(X_base, columns=[f\"x{i+1}\" for i in range(n_features)])\n",
    "    df.insert(0, \"const\", 1.0)\n",
    "\n",
    "    # 2. Generate true parameters\n",
    "    n_cutpoints = n_classes - 1\n",
    "    \n",
    "    # Coefficients (first 5 features have non-zero effects)\n",
    "    beta_true = np.zeros(n_features + 1)  # +1 for intercept\n",
    "    beta_true[0] = 1.0  # Intercept\n",
    "    beta_true[1:6] = np.array([1.5, -2.0, 0.75, 1.25, -0.5]) * beta_scale\n",
    "    \n",
    "    # Cutpoints (sorted for identifiability)\n",
    "    theta_true = np.sort(np.random.randn(n_cutpoints) * class_separation)\n",
    "\n",
    "    # 3. Compute linear predictor\n",
    "    X_mat = df.values\n",
    "    XB = X_mat @ beta_true  # Shape (n_samples,)\n",
    "\n",
    "    # 4. Calculate class probabilities using proportional odds model\n",
    "    z = theta_true[:, None] - XB  # Shape (n_cutpoints, n_samples)\n",
    "    cumulative_probs = 1 / (1 + np.exp(-z))  # CDF values\n",
    "    \n",
    "    # Pad with 0 (left) and 1 (right) for class probabilities\n",
    "    padded_probs = np.vstack([np.zeros((1, n_samples)),\n",
    "                             cumulative_probs,\n",
    "                             np.ones((1, n_samples))])\n",
    "    \n",
    "    # Calculate class probabilities via differences\n",
    "    class_probs = np.diff(padded_probs, axis=0)  # Shape (n_classes, n_samples)\n",
    "    class_probs = class_probs.T  # Shape (n_samples, n_classes)\n",
    "\n",
    "    # 5. Generate ordinal labels\n",
    "    u = np.random.rand(n_samples)\n",
    "    cumulative_probs = np.cumsum(class_probs, axis=1)\n",
    "    y = (u[:, None] < cumulative_probs).argmax(axis=1)\n",
    "\n",
    "    # 6. Add weights and return\n",
    "    df[\"weight\"] = np.random.uniform(0, 100, size=n_samples)\n",
    "    return df, pd.Series(y, name=\"y\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    df, y = create_synthetic_data_linear_regression(p=15)\n",
    "    df, y = create_synthetic_data_ordinal_logit(n_features=15, n_classes=3)\n",
    "    \n",
    "    # print(df.head())\n",
    "    # print(y.head())\n",
    "    print(df.columns)\n",
    "    print(\"df shape:\", df.shape)\n",
    "    print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6aa916f6-72af-46d5-b5ae-db5838f3ff8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() \n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4c7dbf5-7f30-4dc1-865e-5b1ebb9348d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Test Statistic: 28830.65851807347\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\"\n",
    "    A version that returns the log-likelihood components (score & information),\n",
    "    consistent with the logistic code's sign conventions.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def loglike(params: np.ndarray, X: np.ndarray, y: np.ndarray, W: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        (Up to a constant) the log-likelihood for linear regression with normal errors \n",
    "        (ignoring constant terms like -n/2 * log(2*pi*sigma^2)).\n",
    "        \"\"\"\n",
    "        residuals = y - np.dot(X, params)\n",
    "        # Typically: -0.5 * sum of weighted residual^2\n",
    "        return -0.5 * np.dot(W * residuals, residuals)\n",
    "\n",
    "    @staticmethod\n",
    "    def score_function(params: np.ndarray, X: np.ndarray, y: np.ndarray, W: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gradient of the log-likelihood w.r.t. params = X^T [ W * residuals ].\n",
    "        (Positive sign—unlike the SSE gradient, which has a negative sign.)\n",
    "        \"\"\"\n",
    "        residuals = y - np.dot(X, params)\n",
    "        return - 2 * np.dot(X.T, W * residuals)\n",
    "\n",
    "    @staticmethod\n",
    "    def information_matrix(params: np.ndarray, X: np.ndarray, W: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        The *negative* Hessian of the log-likelihood (a.k.a. the 'information').\n",
    "        This is X^T W X, which should be positive (semi-)definite.\n",
    "        \"\"\"\n",
    "        return 2 * np.dot(X.T, W[:, np.newaxis] * X)\n",
    "\n",
    "\n",
    "\n",
    "cands = ['const', 'x1', 'x2', \"x3\"]\n",
    "df[cands]\n",
    "X = np.asarray(df[cands])\n",
    "weights = np.asarray(df['weight'])\n",
    "nobs = df.shape[0]\n",
    "W = (weights / np.sum(weights)) * nobs # normalized weights\n",
    "W = weights\n",
    "W = np.ones(len(y))\n",
    "null_model = np.sum(W * y) / np.sum(W)\n",
    "theta_0 = np.append(null_model, np.zeros(X.shape[1] - 1))\n",
    "# g = LinearRegression.score_function(theta_0, X, y, W)\n",
    "# Is = LinearRegression.information_matrix(theta_0, X,   W)\n",
    "# -g.T.dot(np.linalg.inv(Is)).dot(g)\n",
    "\n",
    "\n",
    "# Compute gradient and Hessian\n",
    "g = LinearRegression.score_function(theta_0, X, y, W)\n",
    "Is = LinearRegression.information_matrix(theta_0, X, W)\n",
    "\n",
    "# CHnage from - to + based on deepseek https://chat.deepseek.com/a/chat/s/fb94e228-cf6a-4cc7-ac69-0d6a1296a761\n",
    "# Score test statistic (corrected)\n",
    "score_statistic = g.T @ np.linalg.inv(Is) @ g\n",
    "\n",
    "print(f\"Score Test Statistic: {score_statistic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a1c03b5-c239-4b50-b7d8-0e479c4a1338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92520c9e-5f38-4f4f-a044-25fc5cd78afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5013386.95049079,  -10197.29878393,   46561.1137199 ],\n",
       "       [ -10197.29878393, 5046034.9089258 ,   13396.88982871],\n",
       "       [  46561.1137199 ,   13396.88982871, 4999795.5964635 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f3580ad-263d-4f2c-8dc6-d380155fded4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.9788268030169283)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = np.sum(W * y) / np.sum(W)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a306c0-9388-4547-a3bb-f77c8d88faba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70e51b48-8cab-4abf-9258-12e575329133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'weight']\n",
      "Finished Var Family: 2\n",
      "Finished Var Family: 3\n",
      "Finished Var Family: 4\n",
      "Finished Var Family: 5\n",
      "Finished Var Family: 6\n",
      "Finished Var Family: 7\n",
      "Finished Var Family: 8\n",
      "Finished Var Family: 9\n",
      "Finished Var Family: 10\n",
      "CPU times: total: 219 ms\n",
      "Wall time: 104 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(692, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df, y = create_synthetic_data_weights(p=15)\n",
    "cands = df.columns[1:].tolist()\n",
    "print(cands)\n",
    "cands.remove('weight')\n",
    "res_noweights, b_bfs_v2, c_bfs_v2= bs7.best_subset_bb_logistic_with_priority(df, y, 100, start=2, stop=10,  candidates=cands ,  forced_vars=['x1', 'x2'])\n",
    "res_noweights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71aa2cd-65db-45d0-8a78-2e9fc656f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y = create_synthetic_data_weights(p=15)\n",
    "cands = df.columns[1:].tolist()\n",
    "cands.remove('weight')\n",
    "print(\"cands:\", cands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bac89346-de49-4d05-911c-26049da08aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15']\n",
      "Finished Var Family: 2\n",
      "Finished Var Family: 3\n",
      "Finished Var Family: 4\n",
      "Finished Var Family: 5\n",
      "Finished Var Family: 6\n",
      "Finished Var Family: 7\n",
      "Finished Var Family: 8\n",
      "Finished Var Family: 9\n",
      "Finished Var Family: 10\n",
      "100\n",
      "CPU times: total: 562 ms\n",
      "Wall time: 159 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(692, 3)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df, y = create_synthetic_data_weights(p=15)\n",
    "cands = df.columns[1:].tolist()\n",
    "cands.remove('weight')\n",
    "print(cands)\n",
    "res_weights, b_bfs_v2, c_bfs_v2= bs7_w.best_subset_bb_logistic_with_priority(df, y, 100, start=2, stop=10,  candidates=cands,  forced_vars=['x1', 'x2'] , weights=df['weight'], normalize=False )\n",
    "# res_weights, b_bfs_v2, c_bfs_v2= bs7_w.best_subset_bb_logistic_with_priority(df, y, 100, start=2, stop=10,  candidates=cands,  forced_vars=['x1', 'x2']  )\n",
    "# res_weights, b_bfs_v2, c_bfs_v2= bs7_w.best_subset_bb_logistic_with_priority(df, y, 100, start=2, stop=10,  candidates=cands  )\n",
    "res_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c009fe63-4646-4448-87f4-dc0ade608d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_dataframes(res_noweights,res_weights)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "237f6193-9034-442d-8637-3e96e9ac11c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var Number</th>\n",
       "      <th>Models</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x1</td>\n",
       "      <td>845,526.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>x2 x1 x4</td>\n",
       "      <td>1,060,642.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>x2 x1 x3</td>\n",
       "      <td>926,207.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>x2 x1 x5</td>\n",
       "      <td>878,598.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>x2 x1 x12</td>\n",
       "      <td>845,779.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>10</td>\n",
       "      <td>x2 x1 x4 x3 x5 x12 x7 x13 x8 x14</td>\n",
       "      <td>1,174,494.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>10</td>\n",
       "      <td>x2 x1 x4 x3 x5 x12 x15 x7 x6 x13</td>\n",
       "      <td>1,174,494.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>10</td>\n",
       "      <td>x2 x1 x4 x3 x5 x12 x9 x6 x13 x11</td>\n",
       "      <td>1,174,493.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>10</td>\n",
       "      <td>x2 x1 x4 x3 x5 x12 x15 x7 x9 x11</td>\n",
       "      <td>1,174,493.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>10</td>\n",
       "      <td>x2 x1 x4 x3 x5 x12 x15 x7 x9 x14</td>\n",
       "      <td>1,174,493.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Var Number                            Models       Scores\n",
       "0             2                             x2 x1   845,526.72\n",
       "13            3                          x2 x1 x4 1,060,642.37\n",
       "12            3                          x2 x1 x3   926,207.66\n",
       "11            3                          x2 x1 x5   878,598.69\n",
       "10            3                         x2 x1 x12   845,779.07\n",
       "..          ...                               ...          ...\n",
       "596          10  x2 x1 x4 x3 x5 x12 x7 x13 x8 x14 1,174,494.48\n",
       "595          10  x2 x1 x4 x3 x5 x12 x15 x7 x6 x13 1,174,494.43\n",
       "594          10  x2 x1 x4 x3 x5 x12 x9 x6 x13 x11 1,174,493.84\n",
       "593          10  x2 x1 x4 x3 x5 x12 x15 x7 x9 x11 1,174,493.72\n",
       "592          10  x2 x1 x4 x3 x5 x12 x15 x7 x9 x14 1,174,493.71\n",
       "\n",
       "[692 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3d429833-ff1f-4ae8-9d2a-72a3811559fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(845526.7225987429)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loglike(params, X, y, W):\n",
    "    q = 2 * y - 1\n",
    "    return np.sum(W * np.log(cdf(q * np.dot(X, params))))\n",
    "\n",
    "def cdf(X):\n",
    "    X = np.asarray(X)\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "def I(params, X, W):\n",
    "    X = np.array(X)\n",
    " \n",
    "    L = cdf(np.dot(X, params))\n",
    "    return -np.dot(W * L * (1 - L) * X.T, X)\n",
    "\n",
    "def score(params, X, y, W):    \n",
    "    L = cdf(np.dot(X, params))\n",
    "    return np.dot(W * (y - L), X)\n",
    "\n",
    "cands = ['const', 'x1', 'x2']\n",
    "df[cands]\n",
    "X = np.asarray(df[cands])\n",
    "weights = np.asarray(df['weight'])\n",
    "nobs = df.shape[0]\n",
    "W = (weights / np.sum(weights)) * nobs # normalized weights\n",
    "W = weights\n",
    "avg = np.sum(W * y) / np.sum(W)\n",
    "null_model = np.log(avg / (1 - avg))\n",
    "theta_0 = np.append(null_model, np.zeros(X.shape[1] - 1))\n",
    "g = score(theta_0, X, y, W)\n",
    "Is = I(theta_0, X, W)\n",
    "-g.T.dot(np.linalg.inv(Is)).dot(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2a4488bb-5111-4f99-9aab-c63ca3be941e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(df['weight'].values, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c12ea72f-9fdb-4c41-b6db-7a53f671cadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Var Family: 2\n",
      "Finished Var Family: 3\n",
      "Finished Var Family: 4\n",
      "Finished Var Family: 5\n",
      "CPU times: total: 2min 50s\n",
      "Wall time: 42.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var Number</th>\n",
       "      <th>Models</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x1</td>\n",
       "      <td>17140.282747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x4</td>\n",
       "      <td>15300.586378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x3</td>\n",
       "      <td>12622.364252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x5</td>\n",
       "      <td>11698.923275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x48</td>\n",
       "      <td>11036.236241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>5</td>\n",
       "      <td>x2 x1 x4 x18 x15</td>\n",
       "      <td>21418.674221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>5</td>\n",
       "      <td>x2 x1 x4 x15 x45</td>\n",
       "      <td>21418.662492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>5</td>\n",
       "      <td>x2 x1 x4 x13 x48</td>\n",
       "      <td>21418.614501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>5</td>\n",
       "      <td>x2 x1 x4 x15 x37</td>\n",
       "      <td>21418.472611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5</td>\n",
       "      <td>x2 x1 x4 x13 x26</td>\n",
       "      <td>21418.281903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Var Number            Models        Scores\n",
       "99            2             x2 x1  17140.282747\n",
       "98            2             x2 x4  15300.586378\n",
       "97            2             x2 x3  12622.364252\n",
       "96            2             x2 x5  11698.923275\n",
       "95            2            x2 x48  11036.236241\n",
       "..          ...               ...           ...\n",
       "304           5  x2 x1 x4 x18 x15  21418.674221\n",
       "303           5  x2 x1 x4 x15 x45  21418.662492\n",
       "302           5  x2 x1 x4 x13 x48  21418.614501\n",
       "301           5  x2 x1 x4 x15 x37  21418.472611\n",
       "300           5  x2 x1 x4 x13 x26  21418.281903\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "a_5, b_5, c_5= bs6.best_subset_bb_logistic_with_priority(df, y, 100, start=2, stop=5,  method=\"dfs\", candidates=df.columns[1:].tolist()) # , forced_vars=['x1', 'x2'])\n",
    "a_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a410f29b-376e-4bca-b765-177fc176a05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Var Family: 2\n",
      "Finished Var Family: 3\n",
      "Finished Var Family: 4\n",
      "Finished Var Family: 5\n",
      "Finished Var Family: 6\n",
      "Finished Var Family: 7\n",
      "Finished Var Family: 8\n",
      "Finished Var Family: 9\n",
      "Finished Var Family: 10\n",
      "Finished Var Family: 11\n",
      "Finished Var Family: 12\n",
      "CPU times: total: 3min 20s\n",
      "Wall time: 53.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_5, b_5, c_5= bs6.best_subset_bb_logistic_with_priority(df, y, 100, start=2, stop=12,   method=\"best_first\",  candidates=df.columns[1:].tolist()) # , forced_vars=['x1', 'x2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3bd07fd1-7a6f-49d8-90a4-18e4176cbad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Var Family: 2\n",
      "Finished Var Family: 3\n",
      "Finished Var Family: 4\n",
      "Finished Var Family: 5\n",
      "Finished Var Family: 6\n",
      "Finished Var Family: 7\n",
      "Finished Var Family: 8\n",
      "Finished Var Family: 9\n",
      "Finished Var Family: 10\n",
      "Finished Var Family: 11\n",
      "Finished Var Family: 12\n",
      "CPU times: total: 24 s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_5, b_5, c_5= bs7.best_subset_bb_logistic_with_priority(df, y, 100, start=2, stop=12,  method=\"best_first\", candidates=df.columns[1:].tolist()) # , forced_vars=['x1', 'x2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e2073761-4df1-4a7e-91f7-8856637130ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302568"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c90e4dc8-bc14-4bbc-9fb3-eafff13e5626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Var Family: 2\n",
      "Finished Var Family: 3\n",
      "Finished Var Family: 4\n",
      "Finished Var Family: 5\n",
      "CPU times: total: 19min 18s\n",
      "Wall time: 5min 10s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var Number</th>\n",
       "      <th>Models</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>x1 x2</td>\n",
       "      <td>17140.282747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x4</td>\n",
       "      <td>15300.586378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x3</td>\n",
       "      <td>12622.364252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x5</td>\n",
       "      <td>11698.923275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>x2 x48</td>\n",
       "      <td>11036.236241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>5</td>\n",
       "      <td>x1 x2 x4 x15 x18</td>\n",
       "      <td>21418.674221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>5</td>\n",
       "      <td>x1 x2 x4 x15 x45</td>\n",
       "      <td>21418.662492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>5</td>\n",
       "      <td>x1 x2 x4 x13 x48</td>\n",
       "      <td>21418.614501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>5</td>\n",
       "      <td>x1 x2 x4 x15 x37</td>\n",
       "      <td>21418.472611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5</td>\n",
       "      <td>x1 x2 x4 x13 x26</td>\n",
       "      <td>21418.281903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Var Number            Models        Scores\n",
       "99            2             x1 x2  17140.282747\n",
       "98            2             x2 x4  15300.586378\n",
       "97            2             x2 x3  12622.364252\n",
       "96            2             x2 x5  11698.923275\n",
       "95            2            x2 x48  11036.236241\n",
       "..          ...               ...           ...\n",
       "304           5  x1 x2 x4 x15 x18  21418.674221\n",
       "303           5  x1 x2 x4 x15 x45  21418.662492\n",
       "302           5  x1 x2 x4 x13 x48  21418.614501\n",
       "301           5  x1 x2 x4 x15 x37  21418.472611\n",
       "300           5  x1 x2 x4 x13 x26  21418.281903\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "a,b = bs3.best_subset_bb_logistic(df, y, 100, start=2, stop=5, candidates=df.columns[1:].tolist()) # , forced_vars=['x1', 'x2'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c5ee61ff-abdb-4e78-9fe3-9cf2066216c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a,b = bs4.best_subset_bb_logistic(df, y, 100, start=2, stop=5, candidates=df.columns[1:].tolist()) # , forced_vars=['x1', 'x2'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6bbeb160-ec5a-4150-b29a-d3ef4f4a6ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Var Size = 2, best_bound = 23402.040\n",
      "Finished Var Size = 3, best_bound = 23402.040\n",
      "Finished Var Size = 4, best_bound = 23402.040\n",
      "Finished Var Size = 5, best_bound = 23402.040\n",
      "Finished Var Size = 6, best_bound = 23402.040\n",
      "Finished Var Size = 7, best_bound = 23402.040\n",
      "Finished Var Size = 8, best_bound = 23402.040\n",
      "Finished Var Size = 9, best_bound = 23402.040\n",
      "Finished Var Size = 10, best_bound = 23402.040\n",
      "Finished Var Size = 11, best_bound = 23402.040\n",
      "Finished Var Size = 12, best_bound = 23402.040\n",
      "Finished Var Size = 13, best_bound = 23402.040\n",
      "Finished Var Size = 14, best_bound = 23402.040\n",
      "Finished Var Size = 15, best_bound = 23402.040\n",
      "Total expansions: 224\n",
      "CPU times: total: 609 ms\n",
      "Wall time: 484 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    " \n",
    "a_par,b = bs5.best_subset_bb_logistic_parallel(df, y, nbest=100, start=2, stop=15,  candidates=df.columns[1:].tolist()) # , forced_vars=['x1', 'x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "47e64910-cbf6-4430-a0ab-5ee1c7fd1644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Result using np.linalg.inv: 395.2539871247952\n",
      "Result using scipy.linalg.cho_solve: 395.2539871187649\n",
      "Result using np.linalg.solve: 395.2539871247954\n",
      "\n",
      "Timing:\n",
      "Time using np.linalg.inv: 0.019066 seconds\n",
      "Time using scipy.linalg.cho_solve: 0.011001 seconds\n",
      "Time using np.linalg.solve: 0.003004 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import time\n",
    "\n",
    "# Generate a random symmetric positive-definite matrix I and a random vector v\n",
    "np.random.seed(42)\n",
    "n = 500  # Matrix size\n",
    "I = np.random.rand(n, n)\n",
    "I = np.dot(I, I.T)  # Make it symmetric positive-definite\n",
    "v = np.random.rand(n)\n",
    "\n",
    "# Method 1: Using np.linalg.inv\n",
    "start_inv = time.time()\n",
    "I_inv = np.linalg.inv(I)\n",
    "result_inv = v.T @ I_inv @ v\n",
    "end_inv = time.time()\n",
    "\n",
    "# Method 2: Using scipy.linalg.cho_solve\n",
    "start_cho = time.time()\n",
    "L = scipy.linalg.cho_factor(I)  # Perform Cholesky factorization\n",
    "result_cho = v.T @ scipy.linalg.cho_solve(L, v)  # Solve using the factorization\n",
    "end_cho = time.time()\n",
    "\n",
    "# Method 3: Using np.linalg.solve\n",
    "start_solve = time.time()\n",
    "result_solve = v.T @ np.linalg.solve(I, v)  # Directly solve the system\n",
    "end_solve = time.time()\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(f\"Result using np.linalg.inv: {result_inv}\")\n",
    "print(f\"Result using scipy.linalg.cho_solve: {result_cho}\")\n",
    "print(f\"Result using np.linalg.solve: {result_solve}\")\n",
    "\n",
    "print(\"\\nTiming:\")\n",
    "print(f\"Time using np.linalg.inv: {end_inv - start_inv:.6f} seconds\")\n",
    "print(f\"Time using scipy.linalg.cho_solve: {end_cho - start_cho:.6f} seconds\")\n",
    "print(f\"Time using np.linalg.solve: {end_solve - start_solve:.6f} seconds\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f395b83b-cbdc-4569-86f7-65ed320e3234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "# Create a heap\n",
    "heap = []\n",
    "heapq.heappush(heap, 10)\n",
    "heapq.heappush(heap, 5)\n",
    "heapq.heappush(heap, 20)\n",
    "type(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3b420cc2-1d3b-446a-bfd5-26255a4a138f",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, key, branches, n, forced_vars=None):\n",
    "        \"\"\"\n",
    "        key: the current subset of variables (excluding 'const')\n",
    "        branches: how many branches remain\n",
    "        n: the target subset size or node parameter\n",
    "        forced_vars: list of variables that must stay in every subset\n",
    "        \"\"\"\n",
    "        if forced_vars is None:\n",
    "            forced_vars = []\n",
    "\n",
    "        self.key = key                # full subset (list of strings)\n",
    "        self.key2 = key[:n]           # partial subset for bounding\n",
    "        self.branch_id = n - branches + 1\n",
    "        self.n = n\n",
    "        self.forced_vars = forced_vars\n",
    "\n",
    "        self.child = []\n",
    "        self.key_list = []\n",
    "        self.has_branches = branches\n",
    "\n",
    "    def add_children(self):\n",
    "        \"\"\"\n",
    "        Create child nodes by popping one feature at a time\n",
    "        but skip if that would drop any forced_var from the subset.\n",
    "        \"\"\"\n",
    "        visit = self.has_branches - 1\n",
    "\n",
    "        for has_branches_new, _ in enumerate(range(visit, 0, -1)):\n",
    "            child_branch_id = self.n - has_branches_new - 1\n",
    "            temp = self.key[:]\n",
    "\n",
    "            # Sanity check: child_branch_id might be out of range\n",
    "            if child_branch_id < 0 or child_branch_id >= len(temp):\n",
    "                continue\n",
    "\n",
    "            removed_feat = temp.pop(child_branch_id)\n",
    "            # If removing that feature leads to losing forced var, skip\n",
    "            if removed_feat in self.forced_vars:\n",
    "                continue\n",
    "\n",
    "            # Also skip if after removal, any forced var is not in temp\n",
    "            if not all(fv in temp for fv in self.forced_vars):\n",
    "                continue\n",
    "\n",
    "            # If we haven't pruned, then child is valid\n",
    "            # We also skip if it doesn't actually reduce the subset size\n",
    "            if len(temp) == self.n - 1:\n",
    "                # This line in the original code was used to skip \n",
    "                # same-size sets, but let's keep it for consistency:\n",
    "                continue\n",
    "\n",
    "            new_node = Node(\n",
    "                temp, \n",
    "                has_branches_new + 2, \n",
    "                self.n, \n",
    "                forced_vars=self.forced_vars\n",
    "            )\n",
    "            self.child.append(new_node)\n",
    "            self.key_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5e7bcccf-22fa-403e-9aff-eebeea7566c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 2\n",
    "n = var \n",
    "root = Node(['x1', 'x2'] , branches=n + 1, n=n, forced_vars=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fba1f920-e34a-41b7-9afc-009e891be66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq = []\n",
    "heapq.heappush(pq, (-250, root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6b51be83-9480-48a0-970d-fc69d3b7864a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-250, <__main__.Node at 0x1a544ce6b60>)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23f8db-ed88-40b4-9b81-dbed6916eba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightGBM",
   "language": "python",
   "name": "lightgbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
